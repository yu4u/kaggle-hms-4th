task:  # task specific config
  img_size: 512
  pool_center: false
  augment: false
  pseudo_prefix: null
  train_pseudo: false
  pseudo_only: false
  sim: false
  head: "none"
  spec_shift: false
  eeg_shift: false
  stratified: false
  random_downsample: false
  downsample_rate: 5
  pretrain: false
  dirname: train_npzs

model:
  arch: 2d  # 2d, 1d
  backbone: tf_efficientnetv2_s.in21k_ft_in1k
  resume_path: null
  ema: false
  swa: false
  freeze_backbone: false
  freeze_end_epoch: 16
  drop_path_rate: 0.0
  drop_rate: 0.0
  attn_drop_rate: 0.0
  stem_stride: 1
  stem_kernel_size: 3

data:
  fold_num: 5
  fold_id: 0
  num_workers: 0
  batch_size: 2
  train_all: false

trainer:
  max_epochs: 32
  devices: "auto"  # list or str, -1 to indicate all available devices
  strategy: "auto"  # ddp
  check_val_every_n_epoch: 1
  sync_batchnorm: false
  accelerator: "cpu"  # cpu, gpu, tpu, ipu, hpu, mps, auto
  precision: 32  # 16, 32, 64, bf16
  gradient_clip_val: null
  accumulate_grad_batches: 1
  deterministic: true
  reload_dataloaders_every_n_epochs: 0

test:
  mode: test  # test or val
  output_dir: preds_results

opt:
  opt: "AdamW"  # SGD, Adam, AdamW...
  lr: 1e-4
  weight_decay: 0.01

scheduler:
  sched: "cosine"
  min_lr: 0.0
  warmup_epochs: 0

loss:
  mixup: 0.0
  cutmix: 0.0

wandb:
  project: hms
  name: null
  fast_dev_run: false
